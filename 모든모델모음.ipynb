{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyHsSVB4nLsZ",
    "outputId": "1204a37f-f047-43e4-ce3f-0f14a34066bd"
   },
   "outputs": [],
   "source": [
    "#이미지 - 랜드마크 - z_value - 유클리드 거리:\n",
    "#이미지 랜마//유클리드//제트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install imblearn\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "# 감정 레이블 정의\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "owTiFxYcc9Pb"
   },
   "source": [
    "# 시드 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ecKbsqUtc96A"
   },
   "outputs": [],
   "source": [
    "# 시드 설정\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "\n",
    "epochs = 100\n",
    "batch_size =32\n",
    "patience_es = 10\n",
    "factor_lr = 0.5\n",
    "patience_lr = 5\n",
    "learning_rate_combined = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kb6yPAKIniOy"
   },
   "source": [
    "# Image Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-LnZ-73IQ4K7",
    "outputId": "b52b14f2-e8f4-4211-f5f9-62346026d8ed"
   },
   "outputs": [],
   "source": [
    "#이미지 - 랜드마크 - z_value - 유클리드 거리:\n",
    "#이미지 랜마//유클리드//제트\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'Image Only'\n",
    "\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [128, 128])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "'''수정함'''\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/0902_128X128/clean_YES_Z_train_shuffled.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/0902_128X128/clean_YES_Z_val_shuffled.tfrecord\"\n",
    "test_tfrecord_file = '/content/drive/MyDrive/0902_128X128/clean_YES_Z_test_shuffled.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "image_shape = (128, 128, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(128,128,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "print(f\"After first MaxPooling2D: {x_image.shape}\")  # 중간 텐서 크기 출력\n",
    "\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "print(f\"After second MaxPooling2D: {x_image.shape}\")  # 중간 텐서 크기 출력\n",
    "\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "print(f\"After third MaxPooling2D: {x_image.shape}\")  # 중간 텐서 크기 출력\n",
    "\n",
    "x_image = Flatten()(x_image)\n",
    "print(f\"After Flatten: {x_image.shape}\")  # Flatten 후 텐서 크기 출력\n",
    "\n",
    "x_image = Dense(64, activation='relu')(x_image)\n",
    "\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.001))(x_image)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs= model_image_input, outputs=model_output)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/0929'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kld68R4InoOS"
   },
   "source": [
    "\n",
    "# LANDMARK ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "E8XJcsfxzpzb",
    "outputId": "3e844198-6c41-4fe4-c0e9-f52eeaacc661"
   },
   "outputs": [],
   "source": [
    "'''#이미지 - 랜드마크 - z_value - 유클리드 거리:\n",
    "#이미지 랜마//유클리드//제트\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')'''\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'Landmark Only'\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "\n",
    "\n",
    "\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "\n",
    "    return  selected_landmarks, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "'''수정함'''\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/0902_128X128/clean_YES_Z_train_shuffled.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/0902_128X128/clean_YES_Z_val_shuffled.tfrecord\"\n",
    "test_tfrecord_file = '/content/drive/MyDrive/0902_128X128/clean_YES_Z_test_shuffled.tfrecord'\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "\n",
    "\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "\n",
    "\n",
    "\n",
    "# 랜드마크 서브넷\n",
    "# 랜드마크 서브넷\n",
    "# 랜드마크 서브넷\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "\n",
    "num_classes = 7  # 분류할 클래스 수\n",
    "x_landmark = Dense(num_classes, activation='softmax', kernel_initializer='he_normal')(x_landmark)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=model_landmark_input, outputs=x_landmark)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, auc, precision_recall_curve, average_precision_score\n",
    "\n",
    "# Assuming you have already defined variables like drive_path, model_name, history, test_dataset, emotion_labels, etc.\n",
    "\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "plt.show()\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_landmarks = []\n",
    "y_test = []\n",
    "\n",
    "for landmark, label in test_dataset:\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_landmarks)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "plt.show()\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "plt.show()\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_landmarks)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "plt.show()\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hQX4UZRcnukE"
   },
   "source": [
    "# Z_VALUES ONLY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "kNJ3HOVGqv87",
    "outputId": "4a0adb1a-d6f9-4f90-8e1d-e44a679a725f"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.layers import Input, Conv1D, MaxPooling1D, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'ZValue Only'\n",
    "\n",
    "# Define landmark indices\n",
    "# Define a function to extract selected landmarks\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return z_product_combinations, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# 모델 정의\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 1-D CNN 모델 구성\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # 1차원 데이터 입력 (1차원 배열 형태)\n",
    "\n",
    "# 완전 연결 레이어\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "model_output = Dense(len(emotion_labels), activation='softmax')(x_z)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=model_z_input, outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for  z_value, label in test_dataset:\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNxuZeCbn0WN"
   },
   "source": [
    "# Image & Landmark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "TLjKUusfn3oj",
    "outputId": "6f488d52-a2f0-4b1d-dedb-81bd037bce4e"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'Image & Landmark'\n",
    "\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return (image, selected_landmarks), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "\n",
    "\n",
    "# 이미지 서브넷\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "\n",
    "# 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "combined = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "\n",
    "combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_image_input, model_landmark_input], outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kLNMirz7n6MT"
   },
   "source": [
    "# Image&Z_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "1WJU_Z_bnzoK",
    "outputId": "f69a95be-9b12-4f0f-ff6b-73b48e0931f3"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'Image & ZValue'\n",
    "\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "\n",
    "\n",
    "\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([x_image, x_z])\n",
    "\n",
    "combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_image_input, model_z_input], outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oYdclA04n_RU"
   },
   "source": [
    "# landmark & z_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "zWccZv7-oCbq",
    "outputId": "64aba8c6-d389-4df8-8fa9-07d18d85ea8e"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'Landmark & ZValue'\n",
    "\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "# 이미지 서브넷\n",
    "\n",
    "\n",
    "# 랜드마크 서브넷\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "\n",
    "# z-값 서브넷\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([x_landmark, x_z])\n",
    "\n",
    "combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (landmark, z_value), label in test_dataset:\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xIn71WWCoEMN"
   },
   "source": [
    "# Image & Landmark & Z_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "nBhGMKf0oI8w",
    "outputId": "cf8ed052-af89-4d9e-93dd-67bc8f849f46"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'Image & Landmark & ZValue'\n",
    "\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "# 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "combined_image_landmark = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "# z-값 서브넷\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([combined_image_landmark, x_z])\n",
    "\n",
    "combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ieoMbHucoNpz"
   },
   "source": [
    "# Image  & Z_value & Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "itBFLVXdoOOL",
    "outputId": "58f2a701-2396-48cb-dde6-ecdf6caf0d1c"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'Image & ZValue & Landmark'\n",
    "\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "\n",
    "# z-값 서브넷\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "# 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "combined_image_z_value= Concatenate()([x_image, x_z])\n",
    "\n",
    "# 랜드마크 서브넷\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([combined_image_z_value, x_landmark])\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-uFTqYA-oRFf"
   },
   "source": [
    "#Z_value & Landmark & Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NAX0onxioTxg",
    "outputId": "1091af93-7959-4b06-ab91-5f8a27ce6ab1"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'ZValue & Landmark & Image'\n",
    "\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "# z-값 서브넷\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "# 랜드마크 서브넷\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "# 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "combined_landmark_z_value= Concatenate()([x_z, x_landmark])\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([combined_landmark_z_value, x_image])\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6nZ6WujwobjM"
   },
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOZjUBg7oa6a"
   },
   "outputs": [],
   "source": [
    "# 현재정확도가장높음66.32\n",
    "# 정규화추가+시각화수정 GAN\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.layers import Dense, Input, Flatten, Conv2D, BatchNormalization, Activation, Dropout, LeakyReLU, GlobalMaxPooling2D, Concatenate, MaxPooling2D, Reshape, Conv2DTranspose\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "import itertools\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "\n",
    "model_name = 'GAN'\n",
    "# 생성된 이미지를 시각화하는 함수 (10 에폭 당 사진 시각화)\n",
    "def visualize_gen_images(epoch, generator, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, [examples, z_comb_dim])\n",
    "    landmark_noise = np.random.normal(0, 1, [examples, input_dim])\n",
    "    img_noise = np.random.normal(0, 1, [examples] + list(image_shape))\n",
    "    generated_images = generator.predict([img_noise, landmark_noise, noise])\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i+1)\n",
    "        plt.imshow(generated_images[i, :, :, 0], interpolation='nearest', cmap='gray_r')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('gan1_0407_generated_image_epoch_%d.png' % epoch)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "# landmark indices 정의\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "\n",
    "# landmark 추출 함수 정의\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "    image = tf.cast(image, tf.float32) * (2. / 255) - 1 # 정확도 높이기 위해 추가\n",
    "\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "def build_generator():\n",
    "    # 이미지 입력\n",
    "    img_input = Input(shape=(48,48,1))\n",
    "\n",
    "    # 랜드마크 입력\n",
    "    landmark_input = Input(shape=(303,))\n",
    "\n",
    "    # z-값 조합 입력\n",
    "    z_comb_input = Input(shape=(56,))\n",
    "\n",
    "    # 이미지 서브넷\n",
    "    x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same')(img_input)\n",
    "    x_image = BatchNormalization()(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.2)(x_image)\n",
    "    x_image = MaxPooling2D((2,2))(x_image)\n",
    "    x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "    x_image = BatchNormalization()(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.3)(x_image)\n",
    "    x_image = MaxPooling2D((2,2))(x_image)\n",
    "    x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "    x_image = BatchNormalization()(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.2)(x_image)\n",
    "    x_image = MaxPooling2D((2,2))(x_image)\n",
    "    x_image = Flatten()(x_image)\n",
    "\n",
    "    # 랜드마크 서브넷\n",
    "    x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(landmark_input)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "    x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "    x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "    # 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "    combined_image_landmark = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "    # z-값 서브넷\n",
    "    x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(z_comb_input)\n",
    "    x_z = BatchNormalization()(x_z)\n",
    "    x_z = Activation('elu')(x_z)\n",
    "    x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "    # 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "    combined = Concatenate()([combined_image_landmark, x_z])\n",
    "    combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "    combined = BatchNormalization()(combined)\n",
    "    combined = Activation('elu')(combined)\n",
    "    combined = Dropout(0.6)(combined)\n",
    "\n",
    "    # 출력 레이어\n",
    "    model_output = Dense(np.prod((48,48,1)), activation='tanh')(combined)\n",
    "    model_output = Reshape((48,48,1))(model_output)\n",
    "\n",
    "    return Model([img_input, landmark_input, z_comb_input], model_output)\n",
    "\n",
    "\n",
    "\n",
    "# 판별자 모델 #계속수정중 #아래가 최대 성능 모델_66.32\n",
    "def build_discriminator():\n",
    "\n",
    "    # 이미지 입력\n",
    "    img_input = Input(shape=(48,48,1))\n",
    "\n",
    "    # 랜드마크 입력\n",
    "    landmark_input = Input(shape=(303,))\n",
    "\n",
    "    # z-값 조합 입력\n",
    "    z_comb_input = Input(shape=(56,))\n",
    "\n",
    "    # 이미지 서브넷\n",
    "    x_image = Flatten(input_shape=(48,48,1))(img_input)\n",
    "    x_image = Dense(128)(x_image)\n",
    "    x_image = LeakyReLU(alpha=0.2)(x_image)\n",
    "\n",
    "    # 랜드마크 서브넷\n",
    "    x_landmark = Dense(101)(landmark_input)\n",
    "    x_landmark = LeakyReLU(alpha=0.2)(x_landmark)\n",
    "\n",
    "    # z-값 서브넷\n",
    "    x_z = Dense(101)(z_comb_input)\n",
    "    x_z = LeakyReLU(alpha=0.2)(x_z)\n",
    "\n",
    "    # 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "    combined = Concatenate()([x_image, x_landmark, x_z])\n",
    "\n",
    "    combined = Dense(256)(combined)\n",
    "    combined = LeakyReLU(alpha=0.2)(combined)\n",
    "\n",
    "    # 출력 레이어\n",
    "    model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "    return Model([img_input, landmark_input, z_comb_input], model_output)\n",
    "\n",
    "\n",
    "# Optimizer\n",
    "optimizer = Adam(0.0002, 0.5)\n",
    "\n",
    "# 판별자 컴파일\n",
    "discriminator = build_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# 생성자 생성\n",
    "generator = build_generator()\n",
    "\n",
    "# 이미지 입력\n",
    "img_input = Input(shape=(48,48,1))\n",
    "\n",
    "# 랜드마크 입력\n",
    "landmark_input = Input(shape=(303,))\n",
    "\n",
    "# z-값 조합 입력\n",
    "z_comb_input = Input(shape=(56,))\n",
    "\n",
    "# 생성자 모델에 입력 전달\n",
    "gen_imgs = generator([img_input, landmark_input, z_comb_input])\n",
    "\n",
    "# 판별자 모델에 이미지 전달\n",
    "valid = discriminator([gen_imgs, landmark_input, z_comb_input])\n",
    "\n",
    "# 결합된 모델 (생성자와 판별자를 쌓음)\n",
    "model_combined = Model([img_input, landmark_input, z_comb_input], valid)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nIyJd_hKogq4"
   },
   "source": [
    "# 1-d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "vnX_T3eiooFq",
    "outputId": "1dbcf833-1d87-4147-8f54-aa608aa4f9c6"
   },
   "outputs": [],
   "source": [
    "# dropout조정하고 dense를 줄임\n",
    "#과적합다시줄여야할듯\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, roc_curve, precision_recall_curve, auc\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = '1-d'\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "# 이미지 서브넷 간소화\n",
    "x_image = Conv2D(16, kernel_size=(3, 3), activation='relu', kernel_regularizer=l2(0.01))(model_image_input)  # 필터 수 감소 및 l2 정규화 계수 감소\n",
    "x_image = MaxPooling2D(pool_size=(2, 2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "x_image = Dense(16, activation='relu')(x_image)  # 차원 축소를 위한 추가 레이어\n",
    "\n",
    "# 랜드마크 서브넷 간소화\n",
    "x_landmark = Dense(50, kernel_regularizer=l2(0.01))(model_landmark_input)  # 뉴런 수 감소 및 l2 정규화 계수 감소\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.7)(x_landmark)  # 드롭아웃 비율 조정\n",
    "x_landmark = Dense(16, activation='relu')(x_landmark)  # 차원 축소를 위한 추가 레이어\n",
    "\n",
    "# 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "combined_image_landmark = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "# z-값 서브넷 간소화\n",
    "x_z = Dense(50, kernel_regularizer=l2(0.01))(model_z_input)  # 뉴런 수 감소\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.7)(x_z)\n",
    "x_z = Dense(16, activation='relu')(x_z)  # 차원 축소를 위한 추가 레이어\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([combined_image_landmark, x_z])\n",
    "\n",
    "combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.65)(combined)\n",
    "\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEheM8gGoxEU"
   },
   "source": [
    "# Freezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oUhKXIHWopP-",
    "outputId": "9ebe94cd-73da-409f-fc9e-7de7838680c5"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, TensorBoard\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'freezing'\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "def extract_image(inputs, label):\n",
    "    return inputs[0], label\n",
    "\n",
    "def extract_landmark(inputs, label):\n",
    "    return inputs[1], label\n",
    "\n",
    "def extract_z_value(inputs, label):\n",
    "    return inputs[2], label\n",
    "\n",
    "# 이미지 데이터셋\n",
    "train_image_dataset = train_dataset.map(extract_image)\n",
    "val_image_dataset = val_dataset.map(extract_image)\n",
    "test_image_dataset = test_dataset.map(extract_image)\n",
    "\n",
    "# 랜드마크 데이터셋\n",
    "train_landmark_dataset = train_dataset.map(extract_landmark)\n",
    "val_landmark_dataset = val_dataset.map(extract_landmark)\n",
    "test_landmark_dataset = test_dataset.map(extract_landmark)\n",
    "\n",
    "# z_value 데이터셋\n",
    "train_z_dataset = train_dataset.map(extract_z_value)\n",
    "val_z_dataset = val_dataset.map(extract_z_value)\n",
    "test_z_dataset = test_dataset.map(extract_z_value)\n",
    "\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "\n",
    "# 랜드마크 서브넷\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "# 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "combined_image_landmark = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "# z-값 서브넷\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([combined_image_landmark, x_z])\n",
    "\n",
    "combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "\n",
    "# 모델 컴파일\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "# 이미지 서브넷 정의 및 학습\n",
    "image_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_image)\n",
    "model_image = Model(inputs=model_image_input, outputs=image_output)\n",
    "model_image.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(), metrics=['accuracy'])\n",
    "model_image.fit(x=train_image_dataset, epochs=epochs, validation_data=val_image_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# 랜드마크 서브넷 정의 및 학습\n",
    "landmark_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_landmark)\n",
    "model_landmark = Model(inputs=model_landmark_input, outputs=landmark_output)\n",
    "model_landmark.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(), metrics=['accuracy'])\n",
    "model_landmark.fit(x=train_landmark_dataset, epochs=epochs, validation_data=val_landmark_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# z-값 서브넷 정의 및 학습\n",
    "z_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_z)\n",
    "model_z = Model(inputs=model_z_input, outputs=z_output)\n",
    "model_z.compile(optimizer=Adam(learning_rate=0.0001), loss=focal_loss(), metrics=['accuracy'])\n",
    "model_z.fit(x=train_z_dataset, epochs=epochs, validation_data=val_z_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "\n",
    "# 서브넷 가중치 동결\n",
    "for layer in model_image.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model_landmark.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in model_z.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# 전체 모델 정의 및 학습\n",
    "\n",
    "model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "\n",
    "\n",
    "# Early stopping callback\n",
    "\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OI1ODbd7oyxu"
   },
   "source": [
    "# weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "sKJn-D1vo1bF",
    "outputId": "5e7d9cf2-44e4-4d61-af8b-006ce3b8398c"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'weighted'\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "def extract_image(inputs, label):\n",
    "    return inputs[0], label\n",
    "\n",
    "def extract_landmark(inputs, label):\n",
    "    return inputs[1], label\n",
    "\n",
    "def extract_z_value(inputs, label):\n",
    "    return inputs[2], label\n",
    "\n",
    "# 이미지 데이터셋\n",
    "train_image_dataset = train_dataset.map(extract_image)\n",
    "val_image_dataset = val_dataset.map(extract_image)\n",
    "test_image_dataset = test_dataset.map(extract_image)\n",
    "\n",
    "# 랜드마크 데이터셋\n",
    "train_landmark_dataset = train_dataset.map(extract_landmark)\n",
    "val_landmark_dataset = val_dataset.map(extract_landmark)\n",
    "test_landmark_dataset = test_dataset.map(extract_landmark)\n",
    "\n",
    "# z_value 데이터셋\n",
    "train_z_dataset = train_dataset.map(extract_z_value)\n",
    "val_z_dataset = val_dataset.map(extract_z_value)\n",
    "test_z_dataset = test_dataset.map(extract_z_value)\n",
    "\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "def build_emotion_classifier():\n",
    "    input_dim = 303  # 랜드마크 데이터의 차원\n",
    "    image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "    z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "    # 입력 레이어\n",
    "    model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "    model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "    model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "    # 이미지 서브넷\n",
    "    x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "    x_image = BatchNormalization(axis=3)(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.3)(x_image)  # new dropout layer\n",
    "    x_image = MaxPooling2D((2,2))(x_image)\n",
    "    x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "    x_image = BatchNormalization(axis=3)(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "    x_image = MaxPooling2D((2,2))(x_image)\n",
    "    x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "    x_image = BatchNormalization(axis=3)(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.3)(x_image)  # new dropout layer\n",
    "    x_image = MaxPooling2D((2,2))(x_image)\n",
    "    x_image = Flatten()(x_image)\n",
    "\n",
    "\n",
    "    # 랜드마크 서브넷\n",
    "    x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "    x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "    x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "    # 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "    combined_image_landmark = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "    # z-값 서브넷\n",
    "    x_z = Dense(101, kernel_regularizer=l2(0.01))(model_z_input)\n",
    "    x_z = BatchNormalization()(x_z)\n",
    "    x_z = Activation('elu')(x_z)\n",
    "    x_z = Dropout(0.5)(x_z)\n",
    "\n",
    "    # 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "    combined = Concatenate()([combined_image_landmark, x_z])\n",
    "\n",
    "    combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "    combined = BatchNormalization()(combined)\n",
    "    combined = Activation('elu')(combined)\n",
    "    combined = Dropout(0.6)(combined)\n",
    "    # 출력 레이어\n",
    "    model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "    # 모델 정의\n",
    "    model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "    # 모델 컴파일\n",
    "    def focal_loss(gamma=2.0, alpha=0.25):\n",
    "        def focal_loss_fixed(y_true, y_pred):\n",
    "            # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "            pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "            pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "            return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "        return focal_loss_fixed\n",
    "\n",
    "    model_combined.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "        loss=focal_loss(),\n",
    "        metrics=['accuracy'])\n",
    "\n",
    "    # 모델 요약\n",
    "    model_combined.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "\n",
    "\n",
    "    # 이미지 서브넷 정의\n",
    "    image_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_image)\n",
    "    model_image = Model(inputs=model_image_input, outputs=image_output)\n",
    "\n",
    "    # 랜드마크 서브넷 정의\n",
    "    landmark_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_landmark)\n",
    "    model_landmark = Model(inputs=model_landmark_input, outputs=landmark_output)\n",
    "\n",
    "    # z-값 서브넷 정의\n",
    "    z_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_z)\n",
    "    model_z = Model(inputs=model_z_input, outputs=z_output)\n",
    "\n",
    "    return model_combined, model_image, model_landmark, model_z\n",
    "\n",
    "def freeze_weights(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "def unfreeze_weights(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "emotion_classifier, model_image, model_landmark, model_z = build_emotion_classifier()\n",
    "\n",
    "# Early stopping callback\n",
    "\n",
    "\n",
    "# Focal loss function\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -tf.reduce_sum(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "freeze_weights(model_landmark)\n",
    "freeze_weights(model_z)\n",
    "model_image.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "model_image.summary()  # Add this line to print the summary\n",
    "\n",
    "\n",
    "\n",
    "model_image.fit(x=train_image_dataset, epochs=epochs, validation_data=val_image_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Compile and train the landmark subnetwork\n",
    "unfreeze_weights(model_landmark)\n",
    "freeze_weights(model_image)\n",
    "freeze_weights(model_z)\n",
    "model_landmark.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "model_landmark.summary()  # Add this line to print the summary\n",
    "\n",
    "model_landmark.fit(x=train_landmark_dataset, epochs=epochs, validation_data=val_landmark_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Compile and train the z-value subnetwork\n",
    "unfreeze_weights(model_z)\n",
    "freeze_weights(model_image)\n",
    "freeze_weights(model_landmark)\n",
    "model_z.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "model_z.summary()  # Add this line to print the summary\n",
    "\n",
    "model_z.fit(x=train_z_dataset, epochs=epochs, validation_data=val_z_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Unfreeze all weights for combined training\n",
    "unfreeze_weights(model_image)\n",
    "unfreeze_weights(model_landmark)\n",
    "unfreeze_weights(model_z)\n",
    "\n",
    "# Compile the combined model\n",
    "emotion_classifier.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "emotion_classifier.summary()\n",
    "\n",
    "# Train the combined model\n",
    "history = emotion_classifier.fit(\n",
    "    x=train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = emotion_classifier.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = emotion_classifier.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = emotion_classifier.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "emotion_classifier.save(model_save_path_h5)\n",
    "emotion_classifier.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "KbDRUl0Lu1HO",
    "outputId": "18b00802-5914-430e-f97e-8648172065b6"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.metrics import roc_auc_score, precision_recall_curve, average_precision_score, roc_curve, auc\n",
    "import pandas as pd\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'weighted'\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "def extract_image(inputs, label):\n",
    "    return inputs[0], label\n",
    "\n",
    "def extract_landmark(inputs, label):\n",
    "    return inputs[1], label\n",
    "\n",
    "def extract_z_value(inputs, label):\n",
    "    return inputs[2], label\n",
    "\n",
    "# 이미지 데이터셋\n",
    "train_image_dataset = train_dataset.map(extract_image)\n",
    "val_image_dataset = val_dataset.map(extract_image)\n",
    "test_image_dataset = test_dataset.map(extract_image)\n",
    "\n",
    "# 랜드마크 데이터셋\n",
    "train_landmark_dataset = train_dataset.map(extract_landmark)\n",
    "val_landmark_dataset = val_dataset.map(extract_landmark)\n",
    "test_landmark_dataset = test_dataset.map(extract_landmark)\n",
    "\n",
    "# z_value 데이터셋\n",
    "train_z_dataset = train_dataset.map(extract_z_value)\n",
    "val_z_dataset = val_dataset.map(extract_z_value)\n",
    "test_z_dataset = test_dataset.map(extract_z_value)\n",
    "\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "\n",
    "# Custom layer to combine tensors with two learnable scalars\n",
    "class CombineLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CombineLayer, self).__init__(**kwargs)\n",
    "        self.a = None\n",
    "        self.b = None\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.a = self.add_weight(shape=(1,), initializer=\"uniform\", trainable=True, name=\"a\")\n",
    "        self.b = self.add_weight(shape=(1,), initializer=\"uniform\", trainable=True, name=\"b\")\n",
    "\n",
    "    def call(self, inputs):\n",
    "        A, B = inputs\n",
    "        return (1 - self.a) * A + self.a * B + (1 - self.b) * A * B\n",
    "\n",
    "def build_model():\n",
    "    input_dim = 303  # Dimension of landmark data\n",
    "    image_shape = (48, 48, 1)  # Shape of image data\n",
    "    z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # Dimension of z-combination\n",
    "\n",
    "    # Input layers\n",
    "    model_landmark_input = Input(shape=(input_dim,))\n",
    "    model_image_input = Input(shape=image_shape)\n",
    "    model_z_input = Input(shape=(z_comb_dim,))\n",
    "\n",
    "    # Image Subnet\n",
    "    x_image = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(model_image_input)\n",
    "    x_image = BatchNormalization(axis=3)(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.1)(x_image)\n",
    "    x_image = MaxPooling2D((2, 2))(x_image)\n",
    "\n",
    "    x_image = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(x_image)\n",
    "    x_image = BatchNormalization(axis=3)(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.1)(x_image)\n",
    "    x_image = MaxPooling2D((2, 2))(x_image)\n",
    "\n",
    "    x_image = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same')(x_image)\n",
    "    x_image = BatchNormalization(axis=3)(x_image)\n",
    "    x_image = Activation('relu')(x_image)\n",
    "    x_image = Dropout(0.4)(x_image)\n",
    "    x_image = MaxPooling2D((2, 2))(x_image)\n",
    "    x_image = Flatten()(x_image)\n",
    "\n",
    "    # Landmark Subnet\n",
    "    x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.5)(x_landmark)\n",
    "\n",
    "    x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.2)(x_landmark)\n",
    "\n",
    "    x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "    x_landmark = BatchNormalization()(x_landmark)\n",
    "    x_landmark = Activation('elu')(x_landmark)\n",
    "    x_landmark = Dropout(0.2)(x_landmark)\n",
    "\n",
    "    # Resize x_image to match x_landmark\n",
    "    x_image_resized = Dense(32)(x_image)\n",
    "\n",
    "    # Combine Image and Landmark Subnets using CombineLayer\n",
    "    combined_image_landmark = CombineLayer(name=\"combine_layer_1\")([x_image_resized, x_landmark])\n",
    "\n",
    "    # z-value Subnet\n",
    "    x_z = Dense(101, kernel_regularizer=l2(0.01))(model_z_input)\n",
    "    x_z = BatchNormalization()(x_z)\n",
    "    x_z = Activation('elu')(x_z)\n",
    "    x_z = Dropout(0.5)(x_z)\n",
    "\n",
    "    # Resize combined_image_landmark to match x_z\n",
    "    combined_image_landmark_resized = Dense(101)(combined_image_landmark)\n",
    "\n",
    "    # Combine all Subnets using CombineLayer\n",
    "    combined = CombineLayer(name=\"combine_layer_2\")([combined_image_landmark_resized, x_z])\n",
    "    combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "    combined = BatchNormalization()(combined)\n",
    "    combined = Activation('relu')(combined)\n",
    "    combined = Dropout(0.5)(combined)\n",
    "\n",
    "    # Output layer\n",
    "    emotion_labels = 7  # Adjust this to match the number of emotion categories\n",
    "    model_output = Dense(emotion_labels, activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "    # Define the combined model\n",
    "    model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "    # Compile the model\n",
    "    learning_rate = 0.00016\n",
    "    model_combined.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "\n",
    "    # 모델 요약\n",
    "    model_combined.summary()\n",
    "\n",
    "    # Early stopping callback\n",
    "\n",
    "\n",
    "    # 이미지 서브넷 정의\n",
    "    image_output = Dense(7, activation='softmax', kernel_regularizer=l2(0.01))(x_image)\n",
    "    model_image = Model(inputs=model_image_input, outputs=image_output)\n",
    "\n",
    "    # 랜드마크 서브넷 정의\n",
    "    landmark_output = Dense(7, activation='softmax', kernel_regularizer=l2(0.01))(x_landmark)\n",
    "    model_landmark = Model(inputs=model_landmark_input, outputs=landmark_output)\n",
    "\n",
    "    # z-값 서브넷 정의\n",
    "    z_output = Dense(7, activation='softmax', kernel_regularizer=l2(0.01))(x_z)\n",
    "    model_z = Model(inputs=model_z_input, outputs=z_output)\n",
    "\n",
    "    return model_combined, model_image, model_landmark, model_z\n",
    "\n",
    "def freeze_weights(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "def unfreeze_weights(model):\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "\n",
    "emotion_classifier, model_image, model_landmark, model_z = build_model()\n",
    "\n",
    "# Early stopping callback\n",
    "\n",
    "\n",
    "# Focal loss function\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        pt = tf.where(tf.equal(y_true, 1), y_pred, 1 - y_pred)\n",
    "        return -tf.reduce_sum(alpha * tf.pow(1. - pt, gamma) * tf.math.log(pt))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "\n",
    "freeze_weights(model_landmark)\n",
    "freeze_weights(model_z)\n",
    "model_image.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "model_image.summary()  # Add this line to print the summary\n",
    "\n",
    "\n",
    "\n",
    "model_image.fit(x=train_image_dataset, epochs=epochs, validation_data=val_image_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Compile and train the landmark subnetwork\n",
    "unfreeze_weights(model_landmark)\n",
    "freeze_weights(model_image)\n",
    "freeze_weights(model_z)\n",
    "model_landmark.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "model_landmark.summary()  # Add this line to print the summary\n",
    "\n",
    "model_landmark.fit(x=train_landmark_dataset, epochs=epochs, validation_data=val_landmark_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Compile and train the z-value subnetwork\n",
    "unfreeze_weights(model_z)\n",
    "freeze_weights(model_image)\n",
    "freeze_weights(model_landmark)\n",
    "model_z.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "model_z.summary()  # Add this line to print the summary\n",
    "\n",
    "model_z.fit(x=train_z_dataset, epochs=epochs, validation_data=val_z_dataset, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Unfreeze all weights for combined training\n",
    "unfreeze_weights(model_image)\n",
    "unfreeze_weights(model_landmark)\n",
    "unfreeze_weights(model_z)\n",
    "\n",
    "# Compile the combined model\n",
    "emotion_classifier.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "emotion_classifier.summary()\n",
    "\n",
    "# Train the combined model\n",
    "history = emotion_classifier.fit(\n",
    "    x=train_dataset,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = emotion_classifier.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = emotion_classifier.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = emotion_classifier.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "emotion_classifier.save(model_save_path_h5)\n",
    "emotion_classifier.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d-hsT7f3Aekc",
    "outputId": "a110ab27-4025-41a5-d2be-911467b5b127"
   },
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = emotion_classifier.evaluate(test_dataset, verbose=1)\n",
    "\n",
    "# Print the results\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vj6nvGOao7I6"
   },
   "source": [
    "# 기본형 Image & Z_valuse & Landmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PFucsRubo8iw"
   },
   "outputs": [],
   "source": [
    "#오후 3시 8분 수정코드 !! 입력 따로 받기 해놓음\n",
    "\n",
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'basic 3 input'\n",
    "# Define landmark indices\n",
    "landmark_indices = [70, 63, 105, 66, 107, 55, 65, 52, 53, 46, 300, 293, 334, 296, 336, 285, 295, 282, 283, 276, 33, 246, 161, 160, 159, 158, 157, 173, 133, 155, 154, 153, 145, 144, 163, 7, 263, 466, 388, 387, 386, 385, 384, 398, 362, 382, 381, 380, 374, 373, 390, 249, 78, 191, 80, 81, 82, 13, 312, 311, 310, 415, 308, 324, 318, 402, 317, 14, 87, 178, 88, 95, 61, 185, 40, 39, 37, 0, 267, 269, 270, 409, 291, 375, 321, 405, 314, 17, 84, 181, 91, 146, 64, 4, 294, 168, 6, 197, 195, 5, 1]\n",
    "# Define a function to extract selected landmarks\n",
    "def extract_selected_landmarks(landmarks):\n",
    "    selected_landmarks = tf.gather(landmarks, indices=landmark_indices, axis=0)\n",
    "    return tf.reshape(selected_landmarks, [len(landmark_indices) * 3])\n",
    "\n",
    "def calculate_z_value_combinations(z_values):\n",
    "    z_combinations = list(itertools.combinations(range(8), 3))\n",
    "    z_product_combinations = []\n",
    "\n",
    "    for indices in z_combinations:\n",
    "        selected_values = tf.gather(z_values, indices)\n",
    "        product = tf.reduce_prod(selected_values)\n",
    "        z_product_combinations.append(product)\n",
    "\n",
    "    return tf.stack(z_product_combinations)\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"landmarks\": tf.io.VarLenFeature(tf.float32),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"z_values\": tf.io.FixedLenFeature([8], tf.float32),  # 기본값 수정\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "    landmarks = tf.sparse.to_dense(parsed_features[\"landmarks\"])\n",
    "    landmarks = tf.reshape(landmarks, [-1, 3])\n",
    "    selected_landmarks = extract_selected_landmarks(landmarks)\n",
    "    selected_landmarks.set_shape([303])\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    z_values = parsed_features[\"z_values\"]\n",
    "    z_product_combinations = calculate_z_value_combinations(z_values)\n",
    "\n",
    "    return (image, selected_landmarks, z_product_combinations), label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "# z-값 조합의 차원\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))\n",
    "\n",
    "# 모델 정의\n",
    "input_dim = 303  # 랜드마크 데이터의 차원\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "z_comb_dim = len(list(itertools.combinations(range(8), 3)))  # z-값 조합의 차원\n",
    "\n",
    "# 입력 레이어\n",
    "model_landmark_input = Input(shape=(input_dim,))  # 랜드마크 입력\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "model_z_input = Input(shape=(z_comb_dim,))  # z-값 조합 입력\n",
    "\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Conv2D(32, kernel_size=(3,3), strides=(1,1), padding='same', input_shape=(48,48,1))(model_image_input)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(64, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.3)(x_image)  # increased dropout rate\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Conv2D(128, kernel_size=(3,3), strides=(1,1), padding='same')(x_image)\n",
    "x_image = BatchNormalization(axis=3)(x_image)\n",
    "x_image = Activation('relu')(x_image)\n",
    "x_image = Dropout(0.2)(x_image)  # new dropout layer\n",
    "x_image = MaxPooling2D((2,2))(x_image)\n",
    "x_image = Flatten()(x_image)\n",
    "\n",
    "# 랜드마크 서브넷\n",
    "x_landmark = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_landmark_input)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)  # Dropout rate 조정\n",
    "\n",
    "x_landmark = Dense(64, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "x_landmark = Dense(32, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(x_landmark)\n",
    "x_landmark = BatchNormalization()(x_landmark)\n",
    "x_landmark = Activation('elu')(x_landmark)\n",
    "x_landmark = Dropout(0.3)(x_landmark)\n",
    "\n",
    "# 이미지 서브넷과 랜드마크 서브넷 합치기\n",
    "combined_image_landmark = Concatenate()([x_image, x_landmark])\n",
    "\n",
    "# z-값 서브넷\n",
    "x_z = Dense(101, kernel_regularizer=l2(0.001), kernel_initializer='he_normal')(model_z_input)\n",
    "x_z = BatchNormalization()(x_z)\n",
    "x_z = Activation('elu')(x_z)\n",
    "x_z = Dropout(0.1)(x_z)\n",
    "\n",
    "# 이미지 서브넷, 랜드마크 서브넷과 z_value 서브넷 합치기\n",
    "combined = Concatenate()([combined_image_landmark, x_z])\n",
    "\n",
    "combined = Dense(128, kernel_regularizer=l2(0.01))(combined)\n",
    "combined = BatchNormalization()(combined)\n",
    "combined = Activation('elu')(combined)\n",
    "combined = Dropout(0.6)(combined)\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(combined)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs=[model_image_input, model_landmark_input, model_z_input], outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "test_landmarks = []\n",
    "test_z_values = []\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for (image, landmark, z_value), label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    test_landmarks.append(landmark)\n",
    "    y_test.extend(label.numpy())\n",
    "    test_z_values.append(z_value)\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images), np.vstack(test_landmarks), np.vstack(test_z_values)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sHpreWeuJmxL"
   },
   "source": [
    "# VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zto-kohhJnaD"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'vggnet16'\n",
    "\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "# 랜드마크와 유클리드 거리 서브넷\n",
    "\n",
    "# 이미지 서브넷\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Lambda, Flatten, Dense\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Assuming emotion_labels is defined somewhere\n",
    "\n",
    "\n",
    "# Concatenate grayscale image to RGB\n",
    "x_image = Lambda(lambda x: tf.concat([x, x, x], axis=-1))(model_image_input)\n",
    "\n",
    "# Load VGG16 model pre-trained on ImageNet, excluding top layers\n",
    "vggnet_model = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze VGG16 layers\n",
    "for layer in vggnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass concatenated RGB image through VGG16\n",
    "x_image = vggnet_model(x_image)\n",
    "\n",
    "# Flatten output and add dense layers\n",
    "x_image = Flatten()(x_image)\n",
    "x_image = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_image)\n",
    "\n",
    "# Output layer for classification\n",
    "model_output = Dense(len(emotion_labels), activation='softmax')(x_image)\n",
    "\n",
    "# Combine inputs and outputs into a model\n",
    "model_combined = Model(inputs=model_image_input, outputs=model_output)\n",
    "\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qW49LTCCJ9rU"
   },
   "source": [
    "#VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CWyFrKLMJ-Y3"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n",
    "# Model name\n",
    "model_name = 'vggnet19'\n",
    "\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "# 랜드마크와 유클리드 거리 서브넷\n",
    "\n",
    "# 이미지 서브넷\n",
    "x_image = Lambda(lambda x: tf.concat([x, x, x], axis=-1))(model_image_input)\n",
    "\n",
    "# Load VGG16 model pre-trained on ImageNet, excluding top layers\n",
    "vggnet_model = VGG19(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze VGG16 layers\n",
    "for layer in vggnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Pass concatenated RGB image through VGG16\n",
    "x_image = vggnet_model(x_image)\n",
    "\n",
    "# Flatten output and add dense layers\n",
    "x_image = Flatten()(x_image)\n",
    "x_image = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_image)\n",
    "\n",
    "# Output layer for classification\n",
    "model_output = Dense(len(emotion_labels), activation='softmax')(x_image)\n",
    "\n",
    "# Combine inputs and outputs into a model\n",
    "model_combined = Model(inputs=model_image_input, outputs=model_output)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOYdTLNEKVWD"
   },
   "source": [
    "# EfficientNetB7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P9UIm1lTKXDR"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import EfficientNetB7\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from itertools import cycle\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'effnetB7'\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "\n",
    "\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "# 랜드마크와 유클리드 거리 서브넷\n",
    "\n",
    "# 이미지 서브넷\n",
    "effnet_model = EfficientNetB7(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# 이미지 입력\n",
    "model_image_input = Input(shape=(48, 48, 1))\n",
    "\n",
    "# 이미지 입력을 EfficientNetB0의 입력 형태에 맞게 조정\n",
    "x_image = Conv2D(3, (1, 1), kernel_regularizer=l2(0.01))(model_image_input)  # 정규화 추가\n",
    "x_image = effnet_model(x_image)\n",
    "\n",
    "x_image = Flatten()(x_image)\n",
    "x_image = Dropout(0.5)(x_image)  # 드롭아웃 추가\n",
    "x_image = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_image)  # 정규화 추가\n",
    "\n",
    "\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_image)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs= model_image_input, outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "okNKYb09KcLI"
   },
   "source": [
    "# 이미지만 resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5O0lY3fJKbmI"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'resnet50'\n",
    "\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "# 랜드마크와 유클리드 거리 서브넷\n",
    "\n",
    "# 이미지 서브넷\n",
    "resnet_model = ResNet50(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "model_image_input = Input(shape=(48, 48, 1))\n",
    "x_image = Conv2D(3, (1, 1))(model_image_input)  # 1x1 convolution to change the number of channels\n",
    "x_image = resnet_model(x_image)\n",
    "\n",
    "x_image = Flatten()(x_image)\n",
    "x_image = Dense(64, activation='relu')(x_image)\n",
    "\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_image)\n",
    "\n",
    "model_combined = Model(inputs=model_image_input, outputs=model_output)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OubNrU0LKtOi"
   },
   "source": [
    "# 이미지만 EfficientNetB0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "07lhJ9oDKtsb"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from itertools import cycle\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "model_name = 'effnetB0'\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "\n",
    "\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "# 랜드마크와 유클리드 거리 서브넷\n",
    "\n",
    "# 이미지 서브넷\n",
    "effnet_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# 이미지 입력\n",
    "model_image_input = Input(shape=(48, 48, 1))\n",
    "\n",
    "# 이미지 입력을 EfficientNetB0의 입력 형태에 맞게 조정\n",
    "x_image = Conv2D(3, (1, 1), kernel_regularizer=l2(0.01))(model_image_input)  # 정규화 추가\n",
    "x_image = effnet_model(x_image)\n",
    "\n",
    "x_image = Flatten()(x_image)\n",
    "x_image = Dropout(0.5)(x_image)  # 드롭아웃 추가\n",
    "x_image = Dense(64, activation='relu', kernel_regularizer=l2(0.01))(x_image)  # 정규화 추가\n",
    "\n",
    "\n",
    "# 출력 레이어\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_image)\n",
    "\n",
    "# 모델 정의\n",
    "model_combined = Model(inputs= model_image_input, outputs=model_output)\n",
    "\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XB25lgsJKzjb"
   },
   "source": [
    "# 이미지만 MobileNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e9CL19WvK4c7"
   },
   "outputs": [],
   "source": [
    "\n",
    "# 필요한 라이브러리 임포트\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, BatchNormalization, Conv2D, MaxPooling2D, Flatten, Activation, Concatenate\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import itertools\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "# 감정 레이블 정의\n",
    "emotion_labels = {\n",
    "    \"happy\": 0, \"sad\": 1, \"anger\": 2, \"surprise\": 3,\n",
    "    \"disgust\": 4, \"neutral\": 5, \"fear\": 6,\n",
    "}\n",
    "\n",
    "model_name = 'monet'\n",
    "\n",
    "# TFRecord 파싱 함수\n",
    "def parse_and_prepare_tfrecord(tfrecord):\n",
    "    features = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"label\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    parsed_features = tf.io.parse_single_example(tfrecord, features)\n",
    "\n",
    "    image = tf.io.decode_jpeg(parsed_features[\"image\"])\n",
    "    image = tf.image.resize(image, [48, 48])\n",
    "    image = tf.image.rgb_to_grayscale(image)\n",
    "    image = tf.expand_dims(image, -1)\n",
    "    image = tf.squeeze(image, axis=-1)\n",
    "\n",
    "\n",
    "    label = tf.one_hot(parsed_features[\"label\"], depth=len(emotion_labels))\n",
    "\n",
    "    return image, label\n",
    "\n",
    "# 데이터셋 로드 및 준비\n",
    "def load_and_prepare_dataset(tfrecord_file, batch_size=None):\n",
    "    dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
    "    dataset = dataset.map(parse_and_prepare_tfrecord)\n",
    "    if batch_size is not None:\n",
    "        dataset = dataset.batch(batch_size)\n",
    "    dataset = dataset.prefetch(tf.data.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "train_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_train.tfrecord\"\n",
    "val_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_val.tfrecord\"\n",
    "test_tfrecord_file = \"/content/drive/MyDrive/clean_0317/Dataset_clean/clean_YES_Z_test.tfrecord\"\n",
    "\n",
    "\n",
    "train_dataset = load_and_prepare_dataset(train_tfrecord_file).batch(batch_size)\n",
    "val_dataset = load_and_prepare_dataset(val_tfrecord_file).batch(batch_size)\n",
    "test_dataset = load_and_prepare_dataset(test_tfrecord_file).batch(batch_size)\n",
    "\n",
    "\n",
    "# 모델 정의\n",
    "image_shape = (48, 48, 1)  # 이미지 데이터의 형태\n",
    "\n",
    "model_image_input = Input(shape=image_shape)  # 이미지 입력\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "# 랜드마크와 유클리드 거리 서브넷\n",
    "\n",
    "# 이미지 서브넷\n",
    "mobilenet_model = MobileNet(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "model_image_input = Input(shape=(48, 48, 1))\n",
    "x_image = Conv2D(3, (1, 1))(model_image_input)  # 1x1 convolution to change the number of channels\n",
    "x_image = mobilenet_model(x_image)\n",
    "\n",
    "x_image = Flatten()(x_image)\n",
    "x_image = BatchNormalization()(x_image)  # 배치 정규화 레이어 추가\n",
    "x_image = Dense(64, activation='relu')(x_image)\n",
    "x_image = Dropout(0.5)(x_image)  # 드롭아웃 레이어 추가\n",
    "\n",
    "model_output = Dense(len(emotion_labels), activation='softmax', kernel_regularizer=l2(0.01))(x_image)\n",
    "\n",
    "model_combined = Model(inputs=model_image_input, outputs=model_output)\n",
    "\n",
    "\n",
    "# 모델 컴파일\n",
    "# 모델 컴파일\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        # y_true: 실제 레이블, y_pred: 모델 예측\n",
    "        pt = y_pred * y_true + (1 - y_pred) * (1 - y_true)\n",
    "        pt = tf.keras.backend.clip(pt, tf.keras.backend.epsilon(), 1.0)  # epsilon 사용\n",
    "        return -tf.keras.backend.sum(alpha * tf.keras.backend.pow(1 - pt, gamma) * tf.keras.backend.log(pt), axis=-1)\n",
    "\n",
    "    return focal_loss_fixed\n",
    "# 모델 컴파일\n",
    "model_combined.compile(\n",
    "    optimizer=Adam(learning_rate=learning_rate_combined),  # decreased learning rate\n",
    "    loss=focal_loss(),\n",
    "    metrics=['accuracy'])\n",
    "\n",
    "# 모델 요약\n",
    "model_combined.summary()\n",
    "\n",
    "# Early stopping callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=patience_es, restore_best_weights=True)\n",
    "train_dataset = train_dataset.shuffle(buffer_size=10000)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=factor_lr, patience=patience_lr, min_lr=1e-6)\n",
    "\n",
    "# 모델 훈련\n",
    "history = model_combined.fit(\n",
    "    x=train_dataset,  # 데이터 증강이 적용된 훈련 데이터셋\n",
    "    epochs=epochs,\n",
    "    validation_data=val_dataset,  # 데이터 증강이 적용되지 않은 검증 데이터셋\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "# Google Drive 경로 설정\n",
    "drive_path = '/content/drive/MyDrive/FINAL'\n",
    "\n",
    "# 디렉토리가 존재하지 않으면 생성\n",
    "if not os.path.exists(drive_path):\n",
    "    os.makedirs(drive_path)\n",
    "\n",
    "# 파일 경로 설정\n",
    "accuracy_loss_path = os.path.join(drive_path, f'{model_name}_accuracy_loss.png')\n",
    "confusion_matrix_path = os.path.join(drive_path, f'{model_name}_confusion_matrix.png')\n",
    "emotion_accuracy_path = os.path.join(drive_path, f'{model_name}_emotion_accuracy.png')\n",
    "precision_recall_curve_path = os.path.join(drive_path, f'{model_name}_precision_recall_curve.png')\n",
    "roc_curve_path = os.path.join(drive_path, f'{model_name}_roc_curve.png')\n",
    "pr_curve_data_path = os.path.join(drive_path, f'{model_name}_pr_curve_data.csv')\n",
    "roc_curve_data_path = os.path.join(drive_path, f'{model_name}_roc_curve_data.csv')\n",
    "model_save_path_h5 = os.path.join(drive_path, f'{model_name}_model.h5')\n",
    "model_save_path_keras = os.path.join(drive_path, f'{model_name}_model.keras')\n",
    "summary_path = os.path.join(drive_path, f'{model_name}_data.txt')\n",
    "\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# 첫 번째 서브플롯 - 정확도\n",
    "plt.subplot(1, 2, 1)  # 1행 2열의 첫 번째 서브플롯\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title(f' Model Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# 두 번째 서브플롯 - 손실\n",
    "plt.subplot(1, 2, 2)  # 1행 2열의 두 번째 서브플롯\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title(f'Model Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.savefig(accuracy_loss_path)\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model_combined.evaluate(test_dataset, verbose=1)\n",
    "print(\"Test Loss:\", test_loss)\n",
    "print(\"Test Accuracy:\", test_accuracy)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "test_images = []\n",
    "\n",
    "\n",
    "y_test = []\n",
    "\n",
    "for image, label in test_dataset:\n",
    "    test_images.append(image)\n",
    "    y_test.extend(label.numpy())\n",
    "\n",
    "y_test_pred = model_combined.predict([np.vstack(test_images)])\n",
    "\n",
    "# 모든 이미지와 랜드마크에 대한 예측 수행\n",
    "y_test = np.argmax(y_test, axis=1)\n",
    "y_test_pred = np.argmax(y_test_pred, axis=1)\n",
    "\n",
    "# 혼돈 행렬 생성 및 시각화\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "plt.figure(figsize=(10, 7))\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='g', cmap='Blues', xticklabels=list(emotion_labels.keys()), yticklabels=list(emotion_labels.keys()))\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('True')\n",
    "plt.title(f'Confusion Matrix')\n",
    "plt.savefig(confusion_matrix_path)\n",
    "\n",
    "# 각각의 감정에 대한 분류 정확도 계산 및 시각화\n",
    "emotion_accuracy_dict = {}\n",
    "for emotion in emotion_labels:\n",
    "    emotion_index = emotion_labels[emotion]\n",
    "    emotion_accuracy = accuracy_score(y_test[y_test == emotion_index], y_test_pred[y_test == emotion_index])\n",
    "    emotion_accuracy_dict[emotion] = emotion_accuracy\n",
    "    print(f\"Accuracy for {emotion}: {emotion_accuracy:.2f}\")\n",
    "\n",
    "# 감정별 정확도를 바 차트로 시각화\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x=list(emotion_accuracy_dict.keys()), y=list(emotion_accuracy_dict.values()))\n",
    "plt.title(f'Accuracy for Each Emotion')\n",
    "plt.savefig(emotion_accuracy_path)\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc, precision_recall_curve\n",
    "\n",
    "# 정밀도, 재현율, F1 스코어 계산\n",
    "precision = precision_score(y_test, y_test_pred, average='macro')\n",
    "recall = recall_score(y_test, y_test_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_test_pred, average='macro')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")\n",
    "\n",
    "# AUC 스코어 계산\n",
    "# 감정 레이블이 다중 클래스이므로, AUC 계산을 위해 one-vs-rest 방식을 적용해야 합니다.\n",
    "# 각 클래스에 대해 확률을 계산해야 하므로, 모델의 예측을 확률로 변경합니다.\n",
    "# Model prediction\n",
    "y_test_prob = model_combined.predict([np.vstack(test_images)])\n",
    "roc_auc = roc_auc_score(y_test, y_test_prob, multi_class='ovr', average=\"macro\")\n",
    "print(f\"{model_name} ROC AUC Score: {roc_auc:.2f}\")\n",
    "\n",
    "# Plot PR curve\n",
    "precision_dict = {}\n",
    "recall_dict = {}\n",
    "average_precision_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    precision_dict[emotion], recall_dict[emotion], _ = precision_recall_curve(y_test == i, y_test_prob[:, i])\n",
    "    average_precision_dict[emotion] = average_precision_score(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(recall_dict[emotion], precision_dict[emotion], lw=2,\n",
    "             label=f'{emotion} (AP={average_precision_dict[emotion]:.2f})')\n",
    "\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title(f'Precision-Recall curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(precision_recall_curve_path)\n",
    "\n",
    "# Plot ROC curve\n",
    "fpr_dict = {}\n",
    "tpr_dict = {}\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    fpr_dict[emotion], tpr_dict[emotion], _ = roc_curve(y_test == i, y_test_prob[:, i])\n",
    "    plt.plot(fpr_dict[emotion], tpr_dict[emotion], lw=2, label=f'{emotion} (area = {auc(fpr_dict[emotion], tpr_dict[emotion]):.2f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('1 - Specificity')\n",
    "plt.ylabel('Sensitivity')\n",
    "plt.title(f'ROC curve')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.savefig(roc_curve_path)\n",
    "\n",
    "# Create empty dataframes to store PR and ROC curve data\n",
    "pr_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AP', 'Recall', 'Precision'])\n",
    "roc_curve_data = pd.DataFrame(columns=['Model', 'Emotion', 'AUC', 'FPR', 'TPR'])\n",
    "\n",
    "# Store PR curve data\n",
    "temp_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for r, p in zip(recall_dict[emotion], precision_dict[emotion]):\n",
    "        temp_data.append({'Model': model_name, 'Emotion': emotion, 'AP': average_precision_dict[emotion], 'Recall': r, 'Precision': p})\n",
    "\n",
    "pr_curve_data = pd.DataFrame(temp_data)\n",
    "\n",
    "# Store ROC curve data\n",
    "temp_roc_data = []\n",
    "\n",
    "for i, emotion in enumerate(emotion_labels):\n",
    "    for f, t in zip(fpr_dict[emotion], tpr_dict[emotion]):\n",
    "        temp_roc_data.append({\n",
    "            'Model': model_name,\n",
    "            'Emotion': emotion,\n",
    "            'AUC': auc(fpr_dict[emotion], tpr_dict[emotion]),\n",
    "            'FPR': f,\n",
    "            'TPR': t\n",
    "        })\n",
    "\n",
    "roc_curve_data = pd.DataFrame(temp_roc_data)\n",
    "pr_curve_data.to_csv(pr_curve_data_path, index=False)\n",
    "roc_curve_data.to_csv(roc_curve_data_path, index=False)\n",
    "\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(f\"Test Loss: {test_loss}\\n\")\n",
    "    f.write(f\"Test Accuracy: {test_accuracy}\\n\")\n",
    "    for emotion, accuracy in emotion_accuracy_dict.items():\n",
    "        f.write(f\"Accuracy for {emotion}: {accuracy:.3f}\\n\")\n",
    "    f.write(f\"Precision: {precision:.3f}\\n\")\n",
    "    f.write(f\"Recall: {recall:.3f}\\n\")\n",
    "    f.write(f\"F1 Score: {f1:.3f}\\n\")\n",
    "    f.write(f\"{model_name} ROC AUC Score: {roc_auc:.3f}\\n\")\n",
    "\n",
    "model_combined.save(model_save_path_h5)\n",
    "model_combined.save(model_save_path_keras)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M930KXnMeP6s"
   },
   "source": [
    "# PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Gi0gohRmeQoo",
    "outputId": "893cd7da-d2b0-495e-d91e-222968c7e8e2"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 파일 목록\n",
    "pr_files = [\n",
    "    '/content/drive/MyDrive/FINAL/1-d_pr_curve_data.csv', '/content/drive/MyDrive/FINAL/basic 3 input_pr_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/freezing_pr_curve_data.csv', '/content/drive/MyDrive/FINAL/GAN_pr_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/monet_pr_curve_data.csv', '/content/drive/MyDrive/FINAL/resnet50_pr_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/vggnet16_pr_curve_data.csv', '/content/drive/MyDrive/FINAL/vggnet19_pr_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/weighted_pr_curve_data.csv', '/content/drive/MyDrive/FINAL/effnetB0_pr_curve_data.csv'\n",
    "]\n",
    "\n",
    "# Print file paths for verification\n",
    "print(\"Checking file paths:\")\n",
    "for file in pr_files:\n",
    "    print(file)\n",
    "\n",
    "# 감정 목록\n",
    "emotions = [\"happy\", \"sad\", \"anger\", \"surprise\", \"disgust\", \"neutral\", \"fear\"]\n",
    "\n",
    "# 각 감정별 평균 AP 저장\n",
    "average_precision_dict = {}\n",
    "\n",
    "# 각 감정별로 PR 곡선 그리기\n",
    "for emotion in emotions:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # 각 파일에 대해 평균 precision-recall 곡선을 계산\n",
    "    model_data = []\n",
    "    for file in pr_files:\n",
    "        df = pd.read_csv(file)\n",
    "        model_name = file.split('/')[-1].split('_pr_curve_data.csv')[0]  # 파일 이름에서 모델 이름 추출\n",
    "        # 해당 감정의 데이터만 추출\n",
    "        emotion_data = df[df['Emotion'] == emotion]\n",
    "\n",
    "        # Precision-Recall 곡선 그리기\n",
    "        precision = emotion_data['Precision']\n",
    "        recall = emotion_data['Recall']\n",
    "        average_precision = np.mean(emotion_data['AP'])\n",
    "        average_precision_dict[emotion] = average_precision\n",
    "        model_data.append((model_name, recall, precision, average_precision))\n",
    "\n",
    "    # AP 높은 순서대로 정렬\n",
    "    model_data.sort(key=lambda x: x[3], reverse=True)\n",
    "\n",
    "    for model_name, recall, precision, average_precision in model_data:\n",
    "        plt.plot(recall, precision, label=f'{model_name} (AP={average_precision:.3f})')\n",
    "\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title(f'Precision-Recall Curve for {emotion} Emotion')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "McyINiCKeRXc"
   },
   "source": [
    "# ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "N2gdghZ6eR6b",
    "outputId": "212f5fe7-8d3a-42ec-ac91-7fc9d227ab86"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 파일 목록\n",
    "roc_files = [\n",
    "    '/content/drive/MyDrive/FINAL/1-d_roc_curve_data.csv', '/content/drive/MyDrive/FINAL/basic 3 input_roc_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/freezing_roc_curve_data.csv','/content/drive/MyDrive/FINAL/GAN_roc_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/monet_roc_curve_data.csv', '/content/drive/MyDrive/FINAL/resnet50_roc_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/vggnet16_roc_curve_data.csv', '/content/drive/MyDrive/FINAL/vggnet19_roc_curve_data.csv',\n",
    "    '/content/drive/MyDrive/FINAL/weighted_roc_curve_data.csv', '/content/drive/MyDrive/FINAL/effnetB0_roc_curve_data.csv'\n",
    "]\n",
    "\n",
    "# 감정 목록\n",
    "emotions = [\"happy\", \"sad\", \"anger\", \"surprise\", \"disgust\", \"neutral\", \"fear\"]\n",
    "\n",
    "# ROC 커브 데이터 저장\n",
    "roc_data = {}\n",
    "\n",
    "for emotion in emotions:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    model_data = []\n",
    "    for file in roc_files:\n",
    "        df = pd.read_csv(file)\n",
    "        model_name = file.split('/')[-1].split('_roc_curve_data.csv')[0]  # Extract model name from file path\n",
    "        emotion_data = df[df['Emotion'] == emotion]\n",
    "\n",
    "\n",
    "        # Check if 'FPR' exists in emotion_data\n",
    "        if 'FPR' in emotion_data.columns:\n",
    "            fpr = emotion_data['FPR']\n",
    "            tpr = emotion_data['TPR']\n",
    "            auc = np.mean(emotion_data['AUC'])\n",
    "            model_data.append((model_name, fpr, tpr, auc))\n",
    "        else:\n",
    "            print(f\"Column 'FPR' not found in {file}\")\n",
    "\n",
    "    model_data.sort(key=lambda x: x[3], reverse=True)\n",
    "\n",
    "    for model_name, fpr, tpr, auc in model_data:\n",
    "        plt.plot(fpr, tpr, label=f'{model_name} (AUC={auc:.3f})')\n",
    "\n",
    "    plt.xlabel('False Positive Rate (FPR)')\n",
    "    plt.ylabel('True Positive Rate (TPR)')\n",
    "    plt.title(f'ROC Curve for {emotion} Emotion')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SVNWVbA25dIe"
   },
   "source": [
    "# 결과 정리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gSqybJlh574t",
    "outputId": "4195adcc-b3b3-4a72-f231-8168c1d36054"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 파일 경로 리스트\n",
    "file_paths = [\n",
    "    '/content/drive/MyDrive/FINAL/Image Only_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/Landmark Only_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/ZValue Only_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/Image & Landmark_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/Image & ZValue_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/Landmark & ZValue_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/Image & Landmark & ZValue_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/Image & ZValue & Landmark_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/ZValue & Landmark & Image_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/1-d_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/GAN_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/basic 3 input_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/freezing_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/weighted_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/effnetB0_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/effnetB7_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/monet_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/resnet50_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/vggnet16_data.txt',\n",
    "    '/content/drive/MyDrive/FINAL/vggnet19_data.txt',\n",
    "\n",
    "]\n",
    "\n",
    "# 결과를 저장할 데이터프레임 생성\n",
    "result_data = pd.DataFrame(columns=[\n",
    "    'Model', 'Test Loss', 'Test Accuracy', 'Accuracy for Happy', 'Accuracy for Sad',\n",
    "    'Accuracy for Anger', 'Accuracy for Surprise', 'Accuracy for Disgust',\n",
    "    'Accuracy for Neutral', 'Accuracy for Fear', 'Precision', 'Recall', 'F1 Score', 'ROC AUC Score'\n",
    "])\n",
    "\n",
    "# 파일을 읽어서 데이터프레임에 추가하는 함수 정의\n",
    "def process_file(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "            # 모델 이름 추출\n",
    "            model_name = file_path.split('/')[-1].split('_data.txt')[0]  # 파일 경로에서 모델 이름 추출\n",
    "\n",
    "            # 성능 지표 추출\n",
    "            test_loss = float(lines[0].split(': ')[1].strip())\n",
    "            test_accuracy = float(lines[1].split(': ')[1].strip())\n",
    "            accuracy_happy = float(lines[2].split(': ')[1].strip())\n",
    "            accuracy_sad = float(lines[3].split(': ')[1].strip())\n",
    "            accuracy_anger = float(lines[4].split(': ')[1].strip())\n",
    "            accuracy_surprise = float(lines[5].split(': ')[1].strip())\n",
    "            accuracy_disgust = float(lines[6].split(': ')[1].strip())\n",
    "            accuracy_neutral = float(lines[7].split(': ')[1].strip())\n",
    "            accuracy_fear = float(lines[8].split(': ')[1].strip())\n",
    "            precision = float(lines[9].split(': ')[1].strip())\n",
    "            recall = float(lines[10].split(': ')[1].strip())\n",
    "            f1_score = float(lines[11].split(': ')[1].strip())\n",
    "            roc_auc_score = float(lines[12].split(': ')[1].strip())\n",
    "\n",
    "            # 데이터프레임에 추가\n",
    "            result_data.loc[len(result_data)] = [\n",
    "                model_name, test_loss, test_accuracy, accuracy_happy, accuracy_sad,\n",
    "                accuracy_anger, accuracy_surprise, accuracy_disgust, accuracy_neutral,\n",
    "                accuracy_fear, precision, recall, f1_score, roc_auc_score\n",
    "            ]\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File not found: {file_path}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {e}\")\n",
    "\n",
    "# 각 파일을 처리하여 데이터프레임에 추가\n",
    "for file_path in file_paths:\n",
    "    process_file(file_path)\n",
    "\n",
    "# 결과를 CSV 파일로 저장\n",
    "result_csv_path = '/content/drive/MyDrive/FINAL/model_performance_comparison.csv'\n",
    "result_data.to_csv(result_csv_path, index=False)\n",
    "\n",
    "# 저장된 CSV 파일 읽기\n",
    "read_result_data = pd.read_csv(result_csv_path)\n",
    "print(read_result_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CvI3vbms5_HU"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
